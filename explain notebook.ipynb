{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da32a134-bb82-4363-a395-20253b2a5fae",
      "metadata": {
        "id": "da32a134-bb82-4363-a395-20253b2a5fae"
      },
      "source": [
        "### 1. Motivation\n",
        "#### What is your dataset?\n",
        "We used three datasets related to Austin Animal Center:\n",
        "- Austin_Animal_Center_Intakes_20250419.csv: records of animals entering the shelter, including intake dates and animal types.\n",
        "- Austin_Animal_Center_Outcomes_20250419.csv: outcome records of animals leaving the shelter (e.g., adoption, euthanasia).\n",
        "- shelter_geocoded_locations.csv: a manually geocoded dataset that maps official shelter addresses in Austin to their corresponding latitude and longitude coordinates, based on data from the Austin Animal Center's official shelter list.\n",
        "- neighbour.json: downloaded from https://data.austintexas.gov/.\n",
        "\n",
        "#### Why did you choose this/these particular dataset(s)?\n",
        "The intake dataset offers a rich, time-stamped record of real-world animal shelter operations. With the help of manually geocoded shelter addresses, we were able to conduct meaningful spatial analysis. This multi-angle approach allows for an accessible and engaging visual story.\n",
        "\n",
        "#### What was your goal for the end user's experience?\n",
        "We want users to understand the patterns behind stray animal intake: when animals enter shelters most frequently, and which shelter regions are under more pressure. The visualizations should guide users from temporal overview to regional insights."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a85fb19-e337-47da-8844-a09367967daa",
      "metadata": {
        "id": "8a85fb19-e337-47da-8844-a09367967daa"
      },
      "source": [
        "### 2. Basic stats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Cleaning & Preprocessing\n",
        "- Merged intake & outcome tables: According to Animal ID.Keeping duplicates for repeat visits.\n",
        "- Date parsing: Converted intake_datetime to proper datetime format.\n",
        "- Time aggregation: Grouped intake counts by month and by shelter region.\n",
        "- Outliers: Removed records with missing animal type or unmatchable shelter data."
      ],
      "metadata": {
        "id": "Ekr4MqXMVOby"
      },
      "id": "Ekr4MqXMVOby"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 读取 Intakes 和 Outcomes 数据集\n",
        "intake_df = pd.read_csv(\"Austin_Animal_Center_Intakes_20250419.csv\")\n",
        "outcome_df = pd.read_csv(\"Austin_Animal_Center_Outcomes_20250419.csv\")\n",
        "\n",
        "def print_basic_info(df, name):\n",
        "    print(f\"datasetname: {name}\")\n",
        "    print(f\"datavolume: {df.shape}\")\n",
        "    print(\"\\n column name\")\n",
        "    print(df.columns.tolist())\n",
        "    print(\"\\n missing value\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\\n sample\")\n",
        "    print(df.head(5))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# 打印 Intakes 数据基本信息\n",
        "print_basic_info(intake_df, \"Intakes\")\n",
        "\n",
        "# 打印 Outcomes 数据基本信息\n",
        "print_basic_info(outcome_df, \"Outcomes\")\n",
        "\n",
        "# 提取 ID 集合\n",
        "intake_ids = set(intake_df[\"Animal ID\"])\n",
        "outcome_ids = set(outcome_df[\"Animal ID\"])\n",
        "\n",
        "# 检查包含关系\n",
        "only_in_intake = intake_ids - outcome_ids\n",
        "only_in_outcome = outcome_ids - intake_ids\n",
        "common_ids = intake_ids & outcome_ids\n",
        "\n",
        "print(f\"🎯 Intake 中总共有 ID 数量: {len(intake_ids)}\")\n",
        "print(f\"🎯 Outcome 中总共有 ID 数量: {len(outcome_ids)}\")\n",
        "print(f\"✅ 两边共有的 ID 数量: {len(common_ids)}\")\n",
        "print(f\"⚠️ 只在 Intake 中出现的 ID: {len(only_in_intake)}\")\n",
        "print(f\"⚠️ 只在 Outcome 中出现的 ID: {len(only_in_outcome)}\")\n",
        "\n",
        "# 是否有重复？\n",
        "intake_duplicates = intake_df[\"Animal ID\"].duplicated().sum()\n",
        "outcome_duplicates = outcome_df[\"Animal ID\"].duplicated().sum()\n",
        "\n",
        "print(f\"\\n🔁 Intake 中重复的 Animal ID 数量: {intake_duplicates}\")\n",
        "print(f\"🔁 Outcome 中重复的 Animal ID 数量: {outcome_duplicates}\")\n",
        "\n",
        "# 每个 ID 在 intake 中出现的次数\n",
        "intake_counts = intake_df[\"Animal ID\"].value_counts()\n",
        "outcome_counts = outcome_df[\"Animal ID\"].value_counts()\n",
        "\n",
        "# 是否所有 ID 只出现一次\n",
        "print(\"Intake 一对一:\", all(intake_counts == 1))\n",
        "print(\"Outcome 一对一:\", all(outcome_counts == 1))\n",
        "\n",
        "# 修复时间格式并统一为 tz-naive（无时区）\n",
        "intake_df[\"DateTime\"] = pd.to_datetime(intake_df[\"DateTime\"], errors=\"coerce\").dt.tz_localize(None)\n",
        "outcome_df[\"DateTime\"] = pd.to_datetime(outcome_df[\"DateTime\"], errors=\"coerce\").dt.tz_localize(None)\n",
        "\n",
        "#对每个动物按时间排序，并编号每一次进出\n",
        "intake_df_sorted = intake_df.sort_values(by=[\"Animal ID\", \"DateTime\"])\n",
        "outcome_df_sorted = outcome_df.sort_values(by=[\"Animal ID\", \"DateTime\"])\n",
        "\n",
        "intake_df_sorted[\"Intake Number\"] = intake_df_sorted.groupby(\"Animal ID\").cumcount() + 1\n",
        "outcome_df_sorted[\"Outcome Number\"] = outcome_df_sorted.groupby(\"Animal ID\").cumcount() + 1\n",
        "\n",
        "#重命名避免合并冲突，保留 MonthYear 和 Date of Birth\n",
        "intake_df_sorted = intake_df_sorted.rename(columns={\n",
        "    \"DateTime\": \"Intake Datetime\",\n",
        "    \"MonthYear\": \"Intake MonthYear\",\n",
        "    \"Sex upon Intake\": \"Sex upon Intake\",\n",
        "    \"Age upon Intake\": \"Age upon Intake\",\n",
        "    \"Intake Type\": \"Intake Type\",\n",
        "    \"Intake Condition\": \"Intake Condition\",\n",
        "    \"Found Location\": \"Found Location\"\n",
        "})\n",
        "\n",
        "outcome_df_sorted = outcome_df_sorted.rename(columns={\n",
        "    \"DateTime\": \"Outcome Datetime\",\n",
        "    \"MonthYear\": \"Outcome MonthYear\",\n",
        "    \"Sex upon Outcome\": \"Sex upon Outcome\",\n",
        "    \"Age upon Outcome\": \"Age upon Outcome\",\n",
        "    \"Outcome Type\": \"Outcome Type\",\n",
        "    \"Outcome Subtype\": \"Outcome Subtype\",\n",
        "    \"Date of Birth\": \"Date of Birth\"\n",
        "})\n",
        "\n",
        "#合并 Intake 和 Outcome（按编号对应）\n",
        "merged_df = pd.merge(\n",
        "    intake_df_sorted,\n",
        "    outcome_df_sorted,\n",
        "    left_on=[\"Animal ID\", \"Intake Number\"],\n",
        "    right_on=[\"Animal ID\", \"Outcome Number\"],\n",
        "    how=\"left\",  # 保留所有 Intake，即使没有匹配的 Outcome\n",
        "    suffixes=(\"_Intake\", \"_Outcome\")\n",
        ")\n",
        "\n",
        "#填充没有 Outcome 的记录\n",
        "merged_df[\"Outcome Number\"] = merged_df[\"Outcome Number\"].fillna(0).astype(int)\n",
        "merged_df[\"Outcome Type\"] = merged_df[\"Outcome Type\"].fillna(\"No Outcome\")\n",
        "merged_df[\"Outcome Subtype\"] = merged_df[\"Outcome Subtype\"].fillna(\"Unknown\")\n",
        "\n",
        "#时间合理性过滤：出所时间应大于等于入所时间或为空\n",
        "merged_df = merged_df[\n",
        "    (merged_df[\"Outcome Datetime\"].isna()) |\n",
        "    (merged_df[\"Outcome Datetime\"] >= merged_df[\"Intake Datetime\"])\n",
        "]\n",
        "\n",
        "#合并字段：优先保留 Intake 数据\n",
        "merged_df[\"Name\"] = merged_df[\"Name_Intake\"].combine_first(merged_df[\"Name_Outcome\"])\n",
        "merged_df[\"Animal Type\"] = merged_df[\"Animal Type_Intake\"].combine_first(merged_df[\"Animal Type_Outcome\"])\n",
        "merged_df[\"Breed\"] = merged_df[\"Breed_Intake\"].combine_first(merged_df[\"Breed_Outcome\"])\n",
        "merged_df[\"Color\"] = merged_df[\"Color_Intake\"].combine_first(merged_df[\"Color_Outcome\"])\n",
        "\n",
        "#填充没有出所的数字字段\n",
        "merged_df[\"Outcome Number\"] = merged_df[\"Outcome Number\"].fillna(0).astype(int)\n",
        "\n",
        "#整理最终字段顺序，保留 Intake/Outcome MonthYear 和 Date of Birth\n",
        "final_df = merged_df[[\n",
        "    \"Animal ID\", \"Name\", \"Animal Type\", \"Date of Birth\", \"Intake Datetime\", \"Intake Type\", \"Intake Condition\",\n",
        "    \"Intake MonthYear\", \"Found Location\", \"Outcome Datetime\", \"Outcome Type\", \"Outcome Subtype\",\n",
        "    \"Outcome MonthYear\", \"Intake Number\", \"Outcome Number\", \"Breed\", \"Color\",\n",
        "    \"Sex upon Intake\", \"Age upon Intake\", \"Sex upon Outcome\", \"Age upon Outcome\"\n",
        "]]\n",
        "\n",
        "# 11. save\n",
        "final_df.to_csv(\"updated_cleaned_merged_animal_data.csv\", index=False)\n",
        "\n",
        "#显示预览（如在 Jupyter 中使用）\n",
        "print(\"合并完成，共 {} 条记录。\".format(len(final_df)))\n",
        "final_df.head(30)\n"
      ],
      "metadata": {
        "id": "byGFZBtfmdra"
      },
      "id": "byGFZBtfmdra",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import googlemaps\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "import math\n",
        "\n",
        "# 输入你的 Google API 密钥\n",
        "api_key = \"AIzaSyDkZJ9NcJjGtc40JG-P3LryIwHS592ii1U\"  # 替换为你的 API 密钥\n",
        "gmaps = googlemaps.Client(key=api_key)\n",
        "\n",
        "# 加载数据文件\n",
        "file_path = 'addresses_part_1.csv'  # 每个人的文件不同\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 假设地址列的名称是 'Formatted Address'\n",
        "addresses = df['Formatted Address'].dropna().unique()\n",
        "\n",
        "# 地理编码函数\n",
        "def geocode_address(address):\n",
        "    try:\n",
        "        # 使用 Google Maps API 进行地理编码\n",
        "        result = gmaps.geocode(address)\n",
        "        if result:\n",
        "            lat = result[0]['geometry']['location']['lat']\n",
        "            lng = result[0]['geometry']['location']['lng']\n",
        "            return address, lat, lng\n",
        "        else:\n",
        "            return address, None, None\n",
        "    except Exception as e:\n",
        "        return address, None, None\n",
        "\n",
        "# 多线程地理编码\n",
        "def geocode_addresses_in_parallel(addresses):\n",
        "    total_addresses = len(addresses)\n",
        "    progress_interval = math.ceil(total_addresses / 10)  # 每处理10%的地址打印一次进度\n",
        "    results = []\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = {executor.submit(geocode_address, address): address for address in addresses}\n",
        "\n",
        "        completed = 0\n",
        "        for future in futures:\n",
        "            result = future.result()\n",
        "            results.append(result)\n",
        "            completed += 1\n",
        "            if completed % progress_interval == 0:\n",
        "                print(f\"已处理 {completed} / {total_addresses} 地址\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# 开始地理编码\n",
        "start_time = time.time()\n",
        "geocoded_data = geocode_addresses_in_parallel(addresses)\n",
        "end_time = time.time()\n",
        "\n",
        "# 将结果转为 DataFrame\n",
        "geocoded_df = pd.DataFrame(geocoded_data, columns=['Address', 'Latitude', 'Longitude'])\n",
        "\n",
        "# 保存地理编码结果到新文件\n",
        "output_file = 'geocoded_addresses_part_1.csv'  # 每个人的输出文件不同\n",
        "geocoded_df.to_csv(output_file, index=False)\n",
        "\n",
        "# 打印用时\n",
        "print(f\"地理编码完成，耗时 {end_time - start_time} 秒。\")\n",
        "\n",
        "# 显示结果预览\n",
        "geocoded_df.head()\n",
        "\n",
        "# 提供文件下载链接\n",
        "output_file"
      ],
      "metadata": {
        "id": "B8Sk2gaFvcQ3"
      },
      "id": "B8Sk2gaFvcQ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Geocoding\n",
        "- Transfer TXT found locations to coordinates through Google Map API.\n",
        "- Shelter matching: Linked each record to a shelter location based on the shelter_name or address field.\n",
        "- Geolocation: Used shelter_geocoded_locations.csv to attach coordinates to each shelter site.\n",
        "- Neighborhood mapping: Mapped coordinates to official Austin neighborhood polygons using spatial joins."
      ],
      "metadata": {
        "id": "AJ5SQmWms8R9"
      },
      "id": "AJ5SQmWms8R9"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 读取原始文件\n",
        "file_path = 'unique_geocoding_ready_addresses.csv'  # 你上传的文件路径\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 假设地址列为 'Formatted Address'\n",
        "addresses = df['Formatted Address'].dropna()\n",
        "\n",
        "# 将数据分成两部分\n",
        "addresses_part_1 = addresses[:len(addresses)//2]\n",
        "addresses_part_2 = addresses[len(addresses)//2:]\n",
        "\n",
        "# 将分割的数据保存为两个 CSV 文件\n",
        "addresses_part_1.to_csv('addresses_part_1.csv', index=False)\n",
        "addresses_part_2.to_csv('addresses_part_2.csv', index=False)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import googlemaps\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "import math\n",
        "\n",
        "# 输入你的 Google API 密钥\n",
        "api_key = \"AIzaSyCdpBuSe2rZT_JwVGgEYLsKGd6SAN0xm5o\"  # 替换为你的 API 密钥\n",
        "gmaps = googlemaps.Client(key=api_key)\n",
        "\n",
        "# 加载数据文件\n",
        "file_path = 'addresses_part_2.csv'  # 每个人的文件不同\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 假设地址列的名称是 'Formatted Address'\n",
        "addresses = df['Formatted Address'].dropna().unique()\n",
        "\n",
        "# 地理编码函数\n",
        "def geocode_address(address):\n",
        "    try:\n",
        "        # 使用 Google Maps API 进行地理编码\n",
        "        result = gmaps.geocode(address)\n",
        "        if result:\n",
        "            lat = result[0]['geometry']['location']['lat']\n",
        "            lng = result[0]['geometry']['location']['lng']\n",
        "            return address, lat, lng\n",
        "        else:\n",
        "            return address, None, None\n",
        "    except Exception as e:\n",
        "        return address, None, None\n",
        "\n",
        "# 多线程地理编码\n",
        "def geocode_addresses_in_parallel(addresses):\n",
        "    total_addresses = len(addresses)\n",
        "    progress_interval = math.ceil(total_addresses / 10)  # 每处理10%的地址打印一次进度\n",
        "    results = []\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = {executor.submit(geocode_address, address): address for address in addresses}\n",
        "\n",
        "        completed = 0\n",
        "        for future in futures:\n",
        "            result = future.result()\n",
        "            results.append(result)\n",
        "            completed += 1\n",
        "            if completed % progress_interval == 0:\n",
        "                print(f\"已处理 {completed} / {total_addresses} 地址\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# 开始地理编码\n",
        "start_time = time.time()\n",
        "geocoded_data = geocode_addresses_in_parallel(addresses)\n",
        "end_time = time.time()\n",
        "\n",
        "# 将结果转为 DataFrame\n",
        "geocoded_df = pd.DataFrame(geocoded_data, columns=['Address', 'Latitude', 'Longitude'])\n",
        "\n",
        "# 保存地理编码结果到新文件\n",
        "output_file = 'geocoded_addresses_part_2.csv'  # 每个人的输出文件不同\n",
        "geocoded_df.to_csv(output_file, index=False)\n",
        "\n",
        "# 打印用时\n",
        "print(f\"地理编码完成，耗时 {end_time - start_time} 秒。\")\n",
        "\n",
        "# 显示结果预览\n",
        "geocoded_df.head()\n",
        "\n",
        "# 提供文件下载链接\n",
        "output_file\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 1. 读取两个地理编码部分数据\n",
        "df_part_1 = pd.read_csv(\"geocoded_addresses_part_1.csv\")\n",
        "df_part_2 = pd.read_csv(\"geocoded_addresses_part_2.csv\")\n",
        "\n",
        "# 2. 合并两个数据集\n",
        "merged_df = pd.concat([df_part_1, df_part_2], ignore_index=True)\n",
        "\n",
        "# 3. 去重操作，防止重复地址\n",
        "merged_df = merged_df.drop_duplicates(subset=['Address'])\n",
        "\n",
        "# 4. 保存合并后的数据\n",
        "merged_df.to_csv(\"geocoded_addresses_merged.csv\", index=False)\n",
        "\n",
        "print(\"合并完成，共 {} 条唯一地址记录。\".format(len(merged_df)))\n",
        "\n"
      ],
      "metadata": {
        "id": "3HuDy6JtsGf4"
      },
      "id": "3HuDy6JtsGf4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset Statistics\n",
        "- Intakes dataset rows: 126,234\n",
        "- Outcomes dataset rows: 124,513\n",
        "- Unique animal types: 5 (Dogs, Cats, Birds, Others, Small Mammals)\n",
        "- Mapped shelter coordinates: Successfully matched to all listed shelters\n",
        "- Time span: October 2013 to April 2025\n",
        "- Number of mapped shelters: 12\n",
        "- 68395 coded locations"
      ],
      "metadata": {
        "id": "t2Oc5DtTVRSm"
      },
      "id": "t2Oc5DtTVRSm"
    },
    {
      "cell_type": "markdown",
      "id": "3b4751e9-260b-4445-8819-f05f0da26df6",
      "metadata": {
        "id": "3b4751e9-260b-4445-8819-f05f0da26df6"
      },
      "source": [
        "### 3. Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dynamic Hotspot Map of Animal Intakes\n",
        "We used Folium’s HeatMapWithTime to animate changes in geographic hotspots across Austin over time. Each frame represents a specific month from October 2013 to April 2025."
      ],
      "metadata": {
        "id": "LVc-URy3OHYT"
      },
      "id": "LVc-URy3OHYT"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "from folium.plugins import HeatMapWithTime, Fullscreen, MeasureControl\n",
        "import branca.colormap as cm\n",
        "\n",
        "# === Step 1: Load data ===\n",
        "df = pd.read_csv(\"merged_data.csv\", parse_dates=[\"Intake Datetime\"])\n",
        "df = df.dropna(subset=[\"Latitude\", \"Longitude\", \"Intake Datetime\"]).copy()\n",
        "df = df[(df[\"Latitude\"].between(-90, 90)) & (df[\"Longitude\"].between(-180, 180))]\n",
        "df[\"Month_Formatted\"] = df[\"Intake Datetime\"].dt.strftime(\"%Y-%m\")\n",
        "\n",
        "# === Step 2: Add weight ===\n",
        "def add_weight(points_list):\n",
        "    from collections import defaultdict\n",
        "    point_counts = defaultdict(int)\n",
        "    weighted = []\n",
        "    for p in points_list:\n",
        "        rounded = (round(p[0], 3), round(p[1], 3))\n",
        "        point_counts[rounded] += 1\n",
        "    for p in points_list:\n",
        "        rounded = (round(p[0], 3), round(p[1], 3))\n",
        "        weighted.append([p[0], p[1], min(point_counts[rounded] * 0.2, 1)])\n",
        "    return weighted\n",
        "\n",
        "time_index = sorted(df[\"Month_Formatted\"].unique())\n",
        "heat_data = [add_weight(df[df[\"Month_Formatted\"] == m][[\"Latitude\", \"Longitude\"]].values.tolist()) for m in time_index]\n",
        "\n",
        "# === Step 3: Setup map ===\n",
        "center = [df[\"Latitude\"].median(), df[\"Longitude\"].median()]\n",
        "m = folium.Map(location=center, zoom_start=12, tiles=\"CartoDB Positron\", control_scale=True)\n",
        "MeasureControl(position=\"bottomright\").add_to(m)\n",
        "\n",
        "# === Step 4: Color gradient ===\n",
        "colors = [\"#c4e9f2\", \"#7fbbdd\", \"#f58b05\", \"#ffc22f\"]\n",
        "colormap = cm.LinearColormap(colors=colors, index=[0, 0.3, 0.6, 1], vmin=0, vmax=1, caption=\"Hotspot Density\")\n",
        "colormap.add_to(m)\n",
        "\n",
        "# === Step 5: Heatmap with time ===\n",
        "HeatMapWithTime(\n",
        "    data=heat_data,\n",
        "    index=time_index,\n",
        "    radius=15,\n",
        "    min_opacity=0.3,\n",
        "    max_opacity=0.9,\n",
        "    gradient={i / 3: colors[i] for i in range(4)},\n",
        "    use_local_extrema=True,\n",
        "    auto_play=True,\n",
        "    display_index=True\n",
        ").add_to(m)\n",
        "\n",
        "# === Step 6: Title box ===\n",
        "title_html = f\"\"\"\n",
        "<div id=\"title-card\" style=\"\n",
        "    position: absolute;\n",
        "    top: 20px;\n",
        "    left: 20px;\n",
        "    z-index: 9999;\n",
        "    background-color: rgba(255,255,255,0.85);\n",
        "    padding: 10px 15px;\n",
        "    border-radius: 8px;\n",
        "    font-family: sans-serif;\n",
        "    box-shadow: 0 0 8px rgba(0,0,0,0.1);\n",
        "    max-width: 300px;\n",
        "    font-size: 13px;\n",
        "\">\n",
        "    <h4 style=\"margin: 0; font-size: 1em;\"><b>Dynamic Hotspot Map of Animal Intakes</b></h4>\n",
        "    <p style=\"margin: 2px 0;\">Monthly distribution of animal intake hotspots</p>\n",
        "    <p style=\"margin: 0;\">Data range: {df[\"Intake Datetime\"].min().strftime('%Y-%m')} to {df[\"Intake Datetime\"].max().strftime('%Y-%m')}</p>\n",
        "</div>\n",
        "\"\"\"\n",
        "m.get_root().html.add_child(folium.Element(title_html))\n",
        "\n",
        "# === Step 7: Final JS fix using MutationObserver ===\n",
        "custom_js = \"\"\"\n",
        "<script>\n",
        "document.addEventListener(\"DOMContentLoaded\", function () {\n",
        "    const map = document.querySelector('.folium-map');\n",
        "    if (map) map.style.position = 'relative';\n",
        "\n",
        "    const observer = new MutationObserver(() => {\n",
        "        const ctrl = document.querySelector('.leaflet-control-timecontrol');\n",
        "        const target = document.querySelector('.leaflet-bottom.leaflet-left');\n",
        "\n",
        "        if (ctrl && target && ctrl.querySelectorAll(\"button\").length > 0) {\n",
        "            // Remove all buttons except play/pause (index 1)\n",
        "            const buttons = ctrl.querySelectorAll(\"button\");\n",
        "            buttons.forEach((btn, i) => {\n",
        "                if (i !== 1) btn.remove();\n",
        "            });\n",
        "\n",
        "            // Remove fps control row\n",
        "            const rows = ctrl.querySelectorAll(\"tr\");\n",
        "            if (rows.length > 1) rows[1].remove();\n",
        "\n",
        "            // Move and style control\n",
        "            target.appendChild(ctrl);\n",
        "            Object.assign(ctrl.style, {\n",
        "                position: 'absolute',\n",
        "                left: '0',\n",
        "                bottom: '0',\n",
        "                margin: '20px',\n",
        "                zIndex: '10000',\n",
        "                background: 'white',\n",
        "                borderRadius: '8px',\n",
        "                padding: '8px',\n",
        "                boxShadow: '0 0 6px rgba(0,0,0,0.2)',\n",
        "                display: 'inline-block',\n",
        "                maxWidth: '600px',\n",
        "                overflow: 'hidden',\n",
        "                transform: 'translateX(0%)'\n",
        "            });\n",
        "\n",
        "            observer.disconnect();\n",
        "        }\n",
        "    });\n",
        "\n",
        "    observer.observe(document.body, { childList: true, subtree: true });\n",
        "});\n",
        "</script>\n",
        "\"\"\"\n",
        "m.get_root().html.add_child(folium.Element(custom_js))\n",
        "\n",
        "# === Step 8: Fullscreen button ===\n",
        "Fullscreen(position=\"topright\").add_to(m)\n",
        "\n",
        "# === Step 9: Save output ===\n",
        "m.save(\"heatmap_final_clean_controls.html\")\n",
        "print(\"✅ Saved: heatmap_final_clean_controls.html\")"
      ],
      "metadata": {
        "id": "36XTPLsZOMGK"
      },
      "id": "36XTPLsZOMGK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Choropleth of Animal Intakes\n",
        "Using a GeoJSON file of Austin neighborhoods, we mapped total intake counts per region and applied a yellow-to-blue gradient using Folium and D3 for visual contrast."
      ],
      "metadata": {
        "id": "-8JjHdjOOoDt"
      },
      "id": "-8JjHdjOOoDt"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "import json\n",
        "from shapely.geometry import shape, Point\n",
        "import branca.colormap as cm\n",
        "\n",
        "# === Step 1: 加载收容数据 ===\n",
        "df = pd.read_csv(\"merged_data.csv\", parse_dates=[\"Intake Datetime\"])\n",
        "df = df.dropna(subset=[\"Latitude\", \"Longitude\"])\n",
        "\n",
        "# === Step 2: 加载 GeoJSON 数据 ===\n",
        "with open(\"Neighborhoods_20250506.geojson\") as f:\n",
        "    gj = json.load(f)\n",
        "\n",
        "# 自动检测区域字段名\n",
        "region_field = next((k for k in gj[\"features\"][0][\"properties\"]\n",
        "                     if \"name\" in k.lower() or \"label\" in k.lower()),\n",
        "                    list(gj[\"features\"][0][\"properties\"].keys())[0])\n",
        "\n",
        "# === Step 3: 将点匹配到区域 ===\n",
        "polygon_map = {f[\"properties\"][region_field]: shape(f[\"geometry\"]) for f in gj[\"features\"]}\n",
        "\n",
        "def assign_region(row):\n",
        "    pt = Point(row[\"Longitude\"], row[\"Latitude\"])\n",
        "    for name, poly in polygon_map.items():\n",
        "        if poly.contains(pt):\n",
        "            return name\n",
        "    return None\n",
        "\n",
        "df[\"region\"] = df.apply(assign_region, axis=1)\n",
        "df = df.dropna(subset=[\"region\"])\n",
        "\n",
        "# === Step 4: 汇总每个区域的收容数量 ===\n",
        "region_counts = df.groupby(\"region\").size().reset_index(name=\"animal_count\")\n",
        "region_dict = region_counts.set_index(\"region\")[\"animal_count\"].to_dict()\n",
        "\n",
        "# 写入 GeoJSON 属性\n",
        "for f in gj[\"features\"]:\n",
        "    rid = f[\"properties\"].get(region_field)\n",
        "    count = region_dict.get(rid, 0)\n",
        "    f[\"properties\"][\"animal_count\"] = int(count)\n",
        "\n",
        "# === Step 5: 创建底图 ===\n",
        "m = folium.Map(location=[30.27, -97.74], zoom_start=11, tiles=\"CartoDB Positron\")\n",
        "\n",
        "# === Step 6: 创建渐变色条（淡黄到主蓝）===\n",
        "colormap = cm.LinearColormap(\n",
        "    colors=[\"#FFF5BF\", \"#639BFF\"],  # 淡黄 → 主蓝\n",
        "    vmin=min(region_dict.values()),\n",
        "    vmax=max(region_dict.values()),\n",
        "    caption=\"Total Animal Intakes by Neighborhood\"\n",
        ")\n",
        "colormap.add_to(m)\n",
        "\n",
        "# === Step 7: 绘制 GeoJson 多边形图层 ===\n",
        "folium.GeoJson(\n",
        "    gj,\n",
        "    style_function=lambda feature: {\n",
        "        \"fillColor\": colormap(feature[\"properties\"].get(\"animal_count\", 0)),\n",
        "        \"color\": \"#A5C8FF\",         # 浅蓝边界\n",
        "        \"weight\": 0.5,\n",
        "        \"fillOpacity\": 0.7\n",
        "    },\n",
        "    tooltip=folium.GeoJsonTooltip(\n",
        "        fields=[region_field, \"animal_count\"],\n",
        "        aliases=[\"Neighborhood:\", \"Animal Intakes:\"],\n",
        "        localize=True,\n",
        "        style=(\n",
        "            \"background-color: #FFF5BF; \"\n",
        "            \"color: #3C3C3C; \"\n",
        "            \"font-family: Comic Sans MS, sans-serif; \"\n",
        "            \"font-size: 12px; \"\n",
        "            \"padding: 6px; border-radius: 5px;\"\n",
        "        )\n",
        "    )\n",
        ").add_to(m)\n",
        "\n",
        "# === Step 8: 添加标题卡片 ===\n",
        "title_html = \"\"\"\n",
        "<div style=\"\n",
        "    position: absolute;\n",
        "    top: 20px;\n",
        "    left: 20px;\n",
        "    z-index: 9999;\n",
        "    background-color: #FFFAF0;\n",
        "    padding: 10px 15px;\n",
        "    border-radius: 10px;\n",
        "    font-family: Comic Sans MS, sans-serif;\n",
        "    box-shadow: 0 0 6px rgba(0,0,0,0.1);\n",
        "    color: #3C3C3C;\n",
        "    font-size: 13px;\n",
        "    max-width: 300px;\n",
        "\">\n",
        "    <h4 style=\"margin: 0; font-size: 16px;\"><b>Choropleth of Animal Intakes</b></h4>\n",
        "    <p style=\"margin: 4px 0;\">Neighborhoods shaded by total intake counts</p>\n",
        "    <p style=\"margin: 0;\">Data source: merged_data.csv</p>\n",
        "</div>\n",
        "\"\"\"\n",
        "m.get_root().html.add_child(folium.Element(title_html))\n",
        "\n",
        "# === Step 9: 导出为 HTML 文件 ===\n",
        "m.save(\"choropleth_yellow_to_blue.html\")\n",
        "print(\"✅ Saved: choropleth_yellow_to_blue.html\")"
      ],
      "metadata": {
        "id": "Kak7YQbAPcE_"
      },
      "id": "Kak7YQbAPcE_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Monthly shelter-intake trend\n",
        "We grouped the dataset by intake month and counted total animal entries. A time series chart was created using Plotly to reflect seasonal and long-term trends."
      ],
      "metadata": {
        "id": "HOhyMYXjPlVs"
      },
      "id": "HOhyMYXjPlVs"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# === Step 1: 加载 intake 数据 ===\n",
        "df = pd.read_csv(\"merged_data.csv\", parse_dates=[\"Intake Datetime\"])\n",
        "df = df.dropna(subset=[\"Intake Datetime\"])\n",
        "df[\"Month\"] = df[\"Intake Datetime\"].dt.to_period(\"M\").astype(str)\n",
        "\n",
        "monthly_counts = (\n",
        "    df.groupby(\"Month\")\n",
        "    .size()\n",
        "    .reset_index(name=\"Count\")\n",
        "    .sort_values(\"Month\")\n",
        ")\n",
        "monthly_counts[\"Month\"] = pd.to_datetime(monthly_counts[\"Month\"])\n",
        "\n",
        "# === Step 2: 自定义颜色样式 ===\n",
        "colors = {\n",
        "    \"background\": \"#FFFAF0\",   # 奶白色\n",
        "    \"line\": \"#639BFF\",         # 折线蓝\n",
        "    \"marker\": \"#FFE25F\",       # 柠檬黄点\n",
        "    \"font\": \"#3C3C3C\"          # 深灰字体\n",
        "}\n",
        "\n",
        "# === Step 3: 构建图表 ===\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=monthly_counts[\"Month\"],\n",
        "    y=monthly_counts[\"Count\"],\n",
        "    mode=\"lines+markers\",\n",
        "    line=dict(color=colors[\"line\"], width=4, shape=\"spline\"),\n",
        "    marker=dict(size=9, color=colors[\"marker\"], line=dict(width=1, color=\"white\")),\n",
        "    hovertemplate=\"Month: %{x|%b %Y}<br>Intakes: %{y}<extra></extra>\"\n",
        "))\n",
        "\n",
        "# === Step 4: 布局与风格 ===\n",
        "fig.update_layout(\n",
        "    title=\"From Streets to Shelter: Monthly Intake Trend\",\n",
        "    xaxis_title=\"Month\",\n",
        "    yaxis_title=\"Number of Animals\",\n",
        "    template=\"simple_white\",\n",
        "    font=dict(family=\"Comic Sans MS, Arial, sans-serif\", size=16, color=colors[\"font\"]),\n",
        "    hovermode=\"x unified\",\n",
        "    margin=dict(t=60, l=60, r=40, b=60),\n",
        "    plot_bgcolor=colors[\"background\"],\n",
        "    paper_bgcolor=colors[\"background\"]\n",
        ")\n",
        "\n",
        "# === Step 5: 导出为 HTML 文件 ===\n",
        "fig.write_html(\"monthly_intake_lemon_highlight_cartoon.html\")\n",
        "print(\"✅ Saved: monthly_intake_lemon_highlight_cartoon.html\")"
      ],
      "metadata": {
        "id": "Ivg9gATUPv3Z"
      },
      "id": "Ivg9gATUPv3Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shelter Coverage & Intakes\n",
        "We made this map to show where each animal shelter can currently reach within 5 km and where most animals are being taken in. This helps us quickly spot places that still lack nearby shelter support, so we know where to add new shelters or send extra help."
      ],
      "metadata": {
        "id": "7EEUxRkzn5wC"
      },
      "id": "7EEUxRkzn5wC"
    },
    {
      "cell_type": "code",
      "source": [
        "import json, warnings\n",
        "import pandas as pd, geopandas as gpd\n",
        "from shapely.geometry import shape\n",
        "import folium, branca\n",
        "from folium.plugins import MarkerCluster\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# basics\n",
        "NEIGH_JSON  = \"neighbour.json\"\n",
        "ANIMAL_CSV  = \"merged_data.csv\"\n",
        "SHELTER_CSV = \"updated_shelter_geocoded_locations.csv\"\n",
        "ICON_PATH   = \"rounded_shelter_icon.png\"\n",
        "OUTCOME_COL      = \"Outcome Type\"\n",
        "ADOPTED_VALUE    = \"Adoption\"\n",
        "\n",
        "\n",
        "CIRCLE_RADIUS = 5000          # shelter radius (m)\n",
        "MAX_ANIMALS   = 6000          # sampling cap\n",
        "COLOR_MIN, COLOR_MAX, N_BINS = \"#fff5bf\", \"#92b7ec\", 7\n",
        "\n",
        "#  读取 neighbourhood.json\n",
        "def load_neighbourhood(path=NEIGH_JSON):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw = json.load(f)\n",
        "    return gpd.GeoDataFrame(\n",
        "        [{\"geometry\": shape(feat[\"the_geom\"]),\n",
        "          **{k: v for k, v in feat.items() if k != \"the_geom\"}} for feat in raw],\n",
        "        crs=\"EPSG:4326\")\n",
        "\n",
        "gdf_neigh = load_neighbourhood()\n",
        "name_col = next(c for c in [\"neighname\",\"NAME\",\"name\",\"neighborhood\"] if c in gdf_neigh)\n",
        "\n",
        "# 读取动物 & shelters\n",
        "animals  = pd.read_csv(ANIMAL_CSV).dropna(subset=[\"Latitude\",\"Longitude\"])\n",
        "if len(animals) > MAX_ANIMALS:\n",
        "    animals = animals.sample(MAX_ANIMALS, random_state=42)\n",
        "shelters = pd.read_csv(SHELTER_CSV)\n",
        "\n",
        "# 动物 → 社区匹配\n",
        "gdf_animals = gpd.GeoDataFrame(\n",
        "    animals, geometry=gpd.points_from_xy(animals.Longitude, animals.Latitude), crs=\"EPSG:4326\")\n",
        "joined = gpd.sjoin(gdf_animals, gdf_neigh[[name_col,\"geometry\"]],\n",
        "                   predicate=\"within\", how=\"left\")\n",
        "cnts = joined.groupby(name_col)[\"Animal ID\"].count().rename(\"animal_cnt\").reset_index()\n",
        "gdf_neigh = gdf_neigh.merge(cnts, on=name_col, how=\"left\").fillna({\"animal_cnt\":0})\n",
        "\n",
        "# colour\n",
        "bins = pd.qcut(gdf_neigh[\"animal_cnt\"], N_BINS, duplicates=\"drop\", retbins=True)[1]\n",
        "cm = branca.colormap.LinearColormap([COLOR_MIN,COLOR_MAX],\n",
        "                                    vmin=bins.min(), vmax=bins.max()\n",
        "                                    ).to_step(len(bins)-1)\n",
        "cm.caption = \"Total Animal Intakes by Neighborhood\"\n",
        "def style_fn(f):\n",
        "    return {\"fillColor\": cm(f[\"properties\"][\"animal_cnt\"]),\n",
        "            \"color\":\"#A5C8FF\",\"weight\":0.6,\"fillOpacity\":0.7}\n",
        "\n",
        "#Folium 地图\n",
        "m = folium.Map(location=[30.27,-97.74], zoom_start=11, tiles=\"cartodbpositron\")\n",
        "\n",
        "folium.GeoJson(\n",
        "    gdf_neigh.to_json(), style_function=style_fn,\n",
        "    tooltip=folium.GeoJsonTooltip(\n",
        "        fields=[name_col,\"animal_cnt\"],\n",
        "        aliases=[\"Neighborhood\",\"Total Intakes\"],\n",
        "        sticky=False, labels=True,\n",
        "        style=(\"background:#FFF5BF;font-family:'Comic Sans MS';\"\n",
        "               \"padding:4px;border-radius:5px;font-size:12px;\"))\n",
        "    ,name=\"Intake Choropleth\").add_to(m)\n",
        "cm.add_to(m)\n",
        "\n",
        "# Info card\n",
        "m.get_root().html.add_child(branca.element.Element(f\"\"\"\n",
        "<div style=\"position:absolute;top:20px;left:20px;z-index:9999;\n",
        "            background:#FFFAF0;padding:10px 15px;border-radius:10px;\n",
        "            font-family:'Comic Sans MS',sans-serif;font-size:13px;color:#3C3C3C;\n",
        "            box-shadow:0 0 6px rgba(0,0,0,0.1);max-width:320px;\">\n",
        "  <h4 style=\"margin:0;font-size:16px;\"><b>Shelter Coverage & Intakes</b></h4>\n",
        "  <p style=\"margin:4px 0;\">Base color: intake counts (yellow→blue)<br/>\n",
        "     Blue circle: {CIRCLE_RADIUS//1000}&nbsp;km shelter radius<br/>\n",
        "     House: shelter location</p>\n",
        "</div>\"\"\"))\n",
        "\n",
        "\n",
        "\n",
        "# MarkerCluster color\n",
        "cluster = MarkerCluster(\n",
        "    name='Stray Animals (cluster)',\n",
        "    icon_create_function=r'''\n",
        "    function(cluster){\n",
        "        var count = cluster.getChildCount();\n",
        "        var color = '#FFA534';          // ≤25  orange\n",
        "        if (count > 100)      { color = '#A3C4F3'; }   // >100  pastel blue\n",
        "        else if (count > 25)  { color = '#FFE599'; }   // 26‑100 pastel yellow\n",
        "\n",
        "        return new L.DivIcon({\n",
        "            html: '<div style=\"background:'+color+';\"><span>'+count+'</span></div>',\n",
        "            className: 'custom-cluster',\n",
        "            iconSize: [40, 40]\n",
        "        });\n",
        "    }\n",
        "    '''\n",
        ").add_to(m)\n",
        "\n",
        "# 把动物点加入聚类（保持不变）\n",
        "for _, r in animals.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[r.Latitude, r.Longitude],\n",
        "        radius=3,\n",
        "        color='#3186CC',\n",
        "        fill=True,\n",
        "        fill_color='#3186CC',\n",
        "        fill_opacity=0.5,\n",
        "        popup=f\"{r['Animal Type']} — {r['Found Location']}\"\n",
        "    ).add_to(cluster)\n",
        "\n",
        "# 追加聚类气泡的 CSS（数字居中、圆形）\n",
        "m.get_root().html.add_child(branca.element.Element(\"\"\"\n",
        "<style>\n",
        ".custom-cluster div{\n",
        "  width:40px; height:40px; line-height:40px; border-radius:20px;\n",
        "  text-align:center; color:#FFFFFF; font-weight:bold;\n",
        "  font-family:Arial,Helvetica,sans-serif;\n",
        "  box-shadow:0 0 0 1.5px #fff inset;\n",
        "}\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "\n",
        "# Individual points\n",
        "COLOR_MAP = {\n",
        "    \"Dog\":   \"#FFA534\",\n",
        "    \"Cat\":   \"#FFE599\",\n",
        "    \"Other\": \"#A3C4F3\"\n",
        "}\n",
        "DEFAULT_COLOR = \"#8CD5FF\"\n",
        "\n",
        "# FeatureGroup\n",
        "type_groups = {}\n",
        "for typ in animals[\"Animal Type\"].unique():\n",
        "    fg = folium.FeatureGroup(name=f\"{typ} (points)\", show=True)\n",
        "    fg.add_to(m)\n",
        "    type_groups[typ] = fg\n",
        "\n",
        "# add points to groups\n",
        "for _, r in animals.iterrows():\n",
        "    typ = r[\"Animal Type\"]\n",
        "    fg  = type_groups.get(typ)\n",
        "    if fg is None:                       # CSV 里出现未知新类型\n",
        "        fg = type_groups.setdefault(\"Other\", folium.FeatureGroup(\n",
        "                name=\"Other (points)\", show=True).add_to(m))\n",
        "    color = COLOR_MAP.get(typ, DEFAULT_COLOR)\n",
        "    folium.CircleMarker(\n",
        "        location=[r.Latitude, r.Longitude],\n",
        "        radius=3.5,\n",
        "        color=color, weight=0.5,\n",
        "        fill=True, fill_color=color, fill_opacity=0.35,\n",
        "        popup=f\"{typ} — {r['Found Location']}\"\n",
        "    ).add_to(fg)\n",
        "\n",
        "#Shelters & Coverage\n",
        "\n",
        "\n",
        "shelter_fg = folium.FeatureGroup(name=\"Shelters & Coverage\", show=True)\n",
        "\n",
        "for _, r in shelters.iterrows():\n",
        "    # 覆盖圈\n",
        "    folium.Circle(\n",
        "        location=[r.latitude, r.longitude],\n",
        "        radius=CIRCLE_RADIUS,\n",
        "        color=\"#629BFD\", weight=1,\n",
        "        fill=True, fill_color=\"#629BFD\", fill_opacity=0.25,\n",
        "        tooltip=r.shelter_name\n",
        "    ).add_to(shelter_fg)\n",
        "\n",
        "    folium.Marker(\n",
        "        location=[r.latitude, r.longitude],\n",
        "        icon=folium.CustomIcon(ICON_PATH, icon_size=(34, 34)),\n",
        "        tooltip=r.shelter_name\n",
        "    ).add_to(shelter_fg)\n",
        "\n",
        "# **关键**：最后再把 FeatureGroup 加到地图，这样它在最上层\n",
        "shelter_fg.add_to(m)\n",
        "\n",
        "\n",
        "folium.LayerControl(position=\"topright\", collapsed=False).add_to(m)\n",
        "\n",
        "m.save(\"shelter_and_animal_intakes.html\")\n",
        "print(\"Map saved: shelter_and_animal_intakes.html\")"
      ],
      "metadata": {
        "id": "w1cxH_8co9-H"
      },
      "id": "w1cxH_8co9-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Intake → Outcome Flow\n",
        "We made this Sankey chart to show where most animals enter the system and where they finally go, so we can see how well the main rescue‑to‑placement pipeline works and which small streams still need help."
      ],
      "metadata": {
        "id": "eSegtOiWqSlG"
      },
      "id": "eSegtOiWqSlG"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, plotly.graph_objects as go\n",
        "\n",
        "df = pd.read_csv(\"merged_data.csv\")\n",
        "\n",
        "src_col = \"Intake Type\"\n",
        "tgt_col = \"Outcome Type\"\n",
        "\n",
        "flow = (df.groupby([src_col, tgt_col])\n",
        "          .size()\n",
        "          .reset_index(name=\"count\"))\n",
        "\n",
        "#  建立 label⇄索引映射\n",
        "labels = pd.concat([flow[src_col], flow[tgt_col]]).unique().tolist()\n",
        "label2id = {lbl:i for i, lbl in enumerate(labels)}\n",
        "\n",
        "flow[\"src_id\"] = flow[src_col].map(label2id)\n",
        "flow[\"tgt_id\"] = flow[tgt_col].map(label2id)\n",
        "\n",
        "# 3) Sankey\n",
        "src_pal = ['#f9cb9c', '#ffe599']\n",
        "tgt_color = '#cfe2f3'\n",
        "\n",
        "# 判断哪些是源节点\n",
        "src_set = set(flow[src_col])\n",
        "\n",
        "# 构造节点颜色\n",
        "node_colors = []\n",
        "src_color_map = {}\n",
        "for i, lbl in enumerate(labels):\n",
        "    if lbl in src_set:\n",
        "        c = src_pal[i % 2]         # 交替选色\n",
        "        src_color_map[lbl] = c\n",
        "        node_colors.append(c)\n",
        "    else:\n",
        "        node_colors.append(tgt_color)\n",
        "\n",
        "# #RRGGBB → rgba(r,g,b,α)\n",
        "def hex2rgba(hexclr, alpha=0.4):\n",
        "    hexclr = hexclr.lstrip('#')\n",
        "    r, g, b = (int(hexclr[j:j+2], 16) for j in (0,2,4))\n",
        "    return f\"rgba({r},{g},{b},{alpha})\"\n",
        "\n",
        "link_colors = [\n",
        "    hex2rgba(src_color_map[ labels[s] ]) for s in flow[\"src_id\"]\n",
        "]\n",
        "\n",
        "\n",
        "fig = go.Figure(go.Sankey(\n",
        "    node=dict(\n",
        "        label     = labels,\n",
        "        pad       = 20,\n",
        "        thickness = 18,\n",
        "        color     = node_colors\n",
        "    ),\n",
        "    link=dict(\n",
        "        source = flow[\"src_id\"],\n",
        "        target = flow[\"tgt_id\"],\n",
        "        value  = flow[\"count\"],\n",
        "        color  = link_colors\n",
        "    )\n",
        "))\n",
        "fig.update_layout(\n",
        "    title_text = \"Austin Animal Intake → Outcome Flow (2014‑2024)\",\n",
        "    font_size  = 12, height = 500,width=860,\n",
        "    font_family='Comic Sans MS',\n",
        "    margin     = dict(l=10, r=10, t=40, b=10),\n",
        "    paper_bgcolor= \"rgba(0,0,0,0)\",   # ← 整张画布透明\n",
        "    plot_bgcolor = \"rgba(0,0,0,0)\",    # ← 绘图区透明\n",
        "    autosize=False\n",
        ")\n",
        "fig.write_html(\n",
        "    \"animal_outcomes_flow_sankey.html\",\n",
        "    include_plotlyjs=\"cdn\",\n",
        "    full_html=False,\n",
        "    config={\"responsive\": True}\n",
        ")\n",
        "print(\"Sankey saved\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4lLWCR0IqjtO"
      },
      "id": "4lLWCR0IqjtO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "975f7071-f600-47a1-a4af-27239609719d",
      "metadata": {
        "id": "975f7071-f600-47a1-a4af-27239609719d"
      },
      "source": [
        "### 4. Genre\n",
        "#### Which genre of data story did you use?\n",
        "We used a Martini Glass narrative structure: The stem is a focused, linear presentation (time series → heatmap animation),followed by an open exploration body (static choropleth map for spatial analysis and comparison).\n",
        "\n",
        "#### Visual Narrative tools used\n",
        "- Graphical highlighting (e.g., saturation of heatmap points over time)\n",
        "- Progressive reveal (the animated heatmap adds time dimension interactively)\n",
        "- Visual grouping (e.g., color mapping in the choropleth for comparing regions)\n",
        "\n",
        "#### Narrative Structure tools used\n",
        "- Author-driven sequence at the start (clear framing of the problem through time trend)\n",
        "- Reader-driven interaction in choropleth map and animation slider\n",
        "- Multi-messaging via annotation blocks and map legends"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0bd7ee9-6b16-4959-b980-e9f821ec6015",
      "metadata": {
        "id": "b0bd7ee9-6b16-4959-b980-e9f821ec6015"
      },
      "source": [
        "###  5. Visualizations\n",
        "To effectively communicate insights from the dataset, we developed a set of visualizations, each tailored to a specific narrative need:\n",
        "\n",
        "We began with an animated heatmap, built using Folium’s HeatMapWithTime, which dynamically displays how the geographic concentration of stray animal pickups evolved over time. This animation reveals consistent hotspots in downtown and east Austin, and shows how stray activity gradually expanded northeast over the years. It adds a powerful spatio-temporal dimension to the narrative, guiding the viewer through changing urban shelter pressures.\n",
        "\n",
        "To offer a cumulative view of shelter burden, we created a neighborhood-level choropleth map using Folium and GeoJSON. The map uses a yellow-to-blue color gradient to represent total intake counts per region. Areas like East Riverside and St. John clearly stand out, allowing readers to compare neighborhood-level disparities in animal intake.\n",
        "\n",
        "We then introduced a monthly time series line chart, constructed with Plotly, to illustrate seasonal trends in shelter intakes from 2013 to 2025."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780e5fb2-e114-49de-b769-77c22e1d176c",
      "metadata": {
        "id": "780e5fb2-e114-49de-b769-77c22e1d176c"
      },
      "source": [
        "### 6. Discussion\n",
        "#### What went well?\n",
        "This project provided a rich opportunity to explore stray animal intake patterns in Austin by combining spatial, temporal, and categorical data through a carefully structured visual narrative.\n",
        "Our use of the Martini Glass structure (Segel & Heer, 2010) was especially helpful in guiding the viewer. The linear sequence of visualizations at the beginning ensured a clear introduction to the problem. As the narrative progressed, we allowed more room for exploration — such as through the interactive intake-condition outcome chart and the Sankey diagram. These elements supported both author-driven messaging and reader-driven discovery, making the overall experience engaging and accessible\n",
        "\n",
        "\n",
        "#### What is still missing? What could be improved? Why?\n",
        "Despite these strengths, several limitations remain. Some of our charts were static, especially the bar and pie charts, which could have been more engaging if built with interactive tools like Plotly or Altair. Additionally, while we conducted extensive exploratory analysis, we did not incorporate predictive modeling. Future versions of this project could include classification models (e.g., predicting adoption likelihood based on intake condition, age, or shelter) to offer more actionable insights for shelter operations. Finally, although we used a manually geocoded list of shelter locations to assess service coverage, the spatial accuracy of some intake data may still be limited by the original address format or missing GPS points. Expanding the dataset or combining it with open civic maps could enhance precision in further iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab3ec31-4b2b-48db-85c8-1dfac627b977",
      "metadata": {
        "id": "3ab3ec31-4b2b-48db-85c8-1dfac627b977"
      },
      "source": [
        "### 7. Contributions\n",
        "- s242613 Yuling Zhai: Geocoding/Heatmap of stray-animal pickup locations/\n",
        "Neighborhood-level intake counts/Monthly shelter-intake trend\n",
        "- s242614 Shimin Huang: Data Cleaning & Preprocessing/Shelter Coverage & Intakes/Intake-Outcome Flow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References\n",
        "Segel & Heer, 2010, Narrative Visualization: Telling Stories with Data\n"
      ],
      "metadata": {
        "id": "IJ7ntjXhU1EI"
      },
      "id": "IJ7ntjXhU1EI"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}